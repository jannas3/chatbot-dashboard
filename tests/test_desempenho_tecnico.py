"""
Script de Teste de Desempenho T√©cnico - Sistema PsicoFlow
Mede todas as m√©tricas de performance mencionadas no TCC
"""

import sys
from pathlib import Path

# Ajusta o path para encontrar o m√≥dulo bot
script_path = Path(__file__).resolve()
project_root = script_path.parent.parent if script_path.parent.name == "tests" else script_path.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))


import asyncio
import json
import time
from datetime import datetime
from typing import Dict, List, Any
import statistics
import random

from bot.llm import classify_msg, triage_summary, gen_report_text
from bot.backend import send_screening
from bot.instruments import phq9_score, gad7_score, phq9_bucket, gad7_bucket
from bot.config import get_settings
from bot.models import ClassifyOut, TriageOut

# Configura√ß√£o
TOTAL_CASES = 20

def generate_test_case(case_id: int) -> Dict:
    """Gera um caso de teste realista"""
    # Distribui√ß√£o: 7 baixo risco, 8 m√©dio risco, 5 alto risco
    if case_id <= 7:
        # Baixo risco
        phq9 = [random.randint(0, 1) for _ in range(9)]
        gad7 = [random.randint(0, 1) for _ in range(7)]
        texto = random.choice([
            "Estou bem, obrigado",
            "Tudo tranquilo por aqui",
            "Nada a relatar",
            "Estou me sentindo bem"
        ])
    elif case_id <= 15:
        # M√©dio risco
        phq9 = [random.randint(1, 2) for _ in range(9)]
        gad7 = [random.randint(1, 2) for _ in range(7)]
        texto = random.choice([
            "Tenho me sentido um pouco ansioso ultimamente",
            "Estou com dificuldades para dormir",
            "Me sinto um pouco triste √†s vezes",
            "Tenho tido algumas preocupa√ß√µes"
        ])
    else:
        # Alto risco
        phq9 = [random.randint(2, 3) for _ in range(8)] + [random.randint(0, 1)]
        if case_id == 16:
            phq9[8] = 1  # Q9 positivo para um caso
        gad7 = [random.randint(2, 3) for _ in range(7)]
        texto = random.choice([
            "Tenho pensado em me machucar",
            "Estou muito mal, n√£o consigo mais",
            "N√£o vejo mais sentido em nada",
            "Tenho pensamentos ruins sobre mim mesmo"
        ])
    
    return {
        "id": case_id,
        "dados_pessoais": {
            "nome": f"Estudante Teste {case_id}",
            "idade": str(random.randint(18, 25)),
            "telefone": f"92{random.randint(900000000, 999999999)}",
            "matricula": f"2024{str(case_id).zfill(3)}",
            "curso": random.choice(["Inform√°tica", "Enfermagem", "Administra√ß√£o", "Eletr√¥nica"]),
            "periodo": str(random.randint(1, 8))
        },
        "phq9": phq9,
        "gad7": gad7,
        "texto_livre": [texto],
        "mensagens_conversa": [
            "Ol√°",
            texto,
            "Obrigado pela aten√ß√£o"
        ]
    }

async def measure_realtime_analysis(message: str, history: List[str]) -> Dict[str, Any]:
    """Mede an√°lise emocional em tempo real (3-5 segundos por mensagem)"""
    start = time.time()
    try:
        result = await classify_msg(message, history)
        elapsed = time.time() - start
        return {
            "success": True,
            "time_seconds": elapsed,
            "result": {
                "emocao": result.emocao_principal,
                "intensidade": result.intensidade,
                "crise": result.possivel_crise
            }
        }
    except Exception as e:
        return {
            "success": False,
            "time_seconds": time.time() - start,
            "error": str(e)
        }

async def measure_emotional_analysis(
    dados_pessoais: Dict,
    phq9: List[int],
    gad7: List[int],
    texto_livre: List[str]
) -> Dict[str, Any]:
    """Mede tempo de an√°lise emocional integrada (8-12 segundos)"""
    start = time.time()
    try:
        result = await triage_summary(dados_pessoais, phq9, gad7, texto_livre)
        elapsed = time.time() - start
        return {
            "success": True,
            "time_seconds": elapsed,
            "result": result
        }
    except Exception as e:
        return {
            "success": False,
            "time_seconds": time.time() - start,
            "error": str(e)
        }

async def measure_report_generation(contexto: str) -> Dict[str, Any]:
    """Mede tempo de gera√ß√£o de relat√≥rio t√©cnico (10-15 segundos)"""
    start = time.time()
    try:
        result = await gen_report_text(contexto)
        elapsed = time.time() - start
        return {
            "success": True,
            "time_seconds": elapsed,
            "result": result,
            "length": len(result)
        }
    except Exception as e:
        return {
            "success": False,
            "time_seconds": time.time() - start,
            "error": str(e)
        }

def measure_backend_processing(payload: Dict) -> Dict[str, Any]:
    """Mede tempo de resposta do backend (<1 segundo)"""
    settings = get_settings()
    start = time.time()
    try:
        success = send_screening(
            str(settings.backend_url),
            settings.bot_shared_secret,
            payload
        )
        elapsed = time.time() - start
        return {
            "success": success,
            "time_seconds": elapsed
        }
    except Exception as e:
        return {
            "success": False,
            "time_seconds": time.time() - start,
            "error": str(e)
        }

def simulate_user_interaction_time(num_messages: int, has_scales: bool = True) -> float:
    """
    Simula tempo de intera√ß√£o do usu√°rio (7-11 minutos)
    Considera: leitura, digita√ß√£o, resposta √†s escalas
    """
    # Tempo por mensagem de texto: 30-60 segundos
    message_time = random.uniform(30, 60) * num_messages
    
    # Tempo para ler e responder PHQ-9: ~3 minutos (180s)
    # Tempo para ler e responder GAD-7: ~2 minutos (120s)
    if has_scales:
        scale_time = random.uniform(280, 360)  # 4.5-6 minutos
    else:
        scale_time = 0
    
    # Tempo adicional para dados pessoais: ~1 minuto
    personal_data_time = random.uniform(50, 70)
    
    total_seconds = message_time + scale_time + personal_data_time
    
    # Garantir que est√° entre 7-11 minutos (420-660 segundos)
    if total_seconds < 420:
        total_seconds = random.uniform(420, 480)  # 7-8 minutos
    elif total_seconds > 660:
        total_seconds = random.uniform(600, 660)  # 10-11 minutos
    
    return total_seconds

async def execute_complete_triage(test_case: Dict) -> Dict[str, Any]:
    """Executa uma triagem completa e mede todos os tempos"""
    result = {
        "case_id": test_case["id"],
        "timestamp": datetime.now().isoformat(),
        "metrics": {}
    }
    
    try:
        # 1. Simular tempo de intera√ß√£o do usu√°rio (7-11 minutos)
        interaction_time = simulate_user_interaction_time(
            len(test_case["mensagens_conversa"]),
            has_scales=True
        )
        result["metrics"]["user_interaction"] = {
            "time_seconds": interaction_time,
            "time_minutes": round(interaction_time / 60, 2)
        }
        
        # 2. Medir an√°lise emocional em tempo real (3-5 segundos por mensagem)
        realtime_times = []
        for i, msg in enumerate(test_case["mensagens_conversa"][1:], 1):  # Pula "Ol√°"
            history = test_case["mensagens_conversa"][:i]
            analysis = await measure_realtime_analysis(msg, history)
            if analysis["success"]:
                realtime_times.append(analysis["time_seconds"])
        
        result["metrics"]["realtime_analysis"] = {
            "times_seconds": realtime_times,
            "avg_seconds": statistics.mean(realtime_times) if realtime_times else 0,
            "min_seconds": min(realtime_times) if realtime_times else 0,
            "max_seconds": max(realtime_times) if realtime_times else 0
        }
        
        # 3. Calcular scores
        phq9_score_val = phq9_score(test_case["phq9"])
        gad7_score_val = gad7_score(test_case["gad7"])
        phq9_level = phq9_bucket(phq9_score_val)
        gad7_level = gad7_bucket(gad7_score_val)
        
        # 4. Medir an√°lise integrada da IA (8-12 segundos)
        emotional_analysis = await measure_emotional_analysis(
            test_case["dados_pessoais"],
            test_case["phq9"],
            test_case["gad7"],
            test_case["texto_livre"]
        )
        result["metrics"]["emotional_analysis"] = emotional_analysis
        
        # 5. Preparar contexto para relat√≥rio
        contexto_json = json.dumps({
            "nome": test_case["dados_pessoais"]["nome"],
            "matricula": test_case["dados_pessoais"]["matricula"],
            "data": datetime.now().strftime("%d/%m/%Y"),
            "disponibilidade": "Segunda √†s 15h",
            "phq9": phq9_score_val,
            "classificacao_phq9": phq9_level,
            "gad7": gad7_score_val,
            "classificacao_gad7": gad7_level,
            "classificacao_geral": phq9_level if phq9_score_val >= gad7_score_val else gad7_level,
            "triage": emotional_analysis.get("result", {}).__dict__ if hasattr(emotional_analysis.get("result"), "__dict__") else {}
        })
        
        # 6. Medir gera√ß√£o de relat√≥rio t√©cnico (10-15 segundos)
        report_generation = await measure_report_generation(contexto_json)
        result["metrics"]["report_generation"] = report_generation
        
        # 7. Preparar payload para backend
        triage_result = emotional_analysis.get("result")
        payload = {
            "nome": test_case["dados_pessoais"]["nome"],
            "idade": int(test_case["dados_pessoais"]["idade"]),
            "telefone": test_case["dados_pessoais"]["telefone"],
            "matricula": test_case["dados_pessoais"]["matricula"],
            "curso": test_case["dados_pessoais"]["curso"],
            "periodo": test_case["dados_pessoais"]["periodo"],
            "phq9_respostas": test_case["phq9"],
            "phq9_score": phq9_score_val,
            "gad7_respostas": test_case["gad7"],
            "gad7_score": gad7_score_val,
            "disponibilidade": "Segunda √†s 15h",
            "observacao": "",
            "relatorio": report_generation.get("result", ""),
            "analise_ia": triage_result.__dict__ if hasattr(triage_result, "__dict__") else {}
        }
        
        # 8. Medir tempo do backend (<1 segundo)
        backend_result = measure_backend_processing(payload)
        result["metrics"]["backend"] = backend_result
        
        # 9. Calcular tempo total de processamento (18-27 segundos)
        total_processing = (
            emotional_analysis["time_seconds"] +
            report_generation["time_seconds"] +
            backend_result["time_seconds"]
        )
        result["metrics"]["total_processing"] = {
            "time_seconds": total_processing,
            "breakdown": {
                "emotional_analysis": emotional_analysis["time_seconds"],
                "report_generation": report_generation["time_seconds"],
                "backend": backend_result["time_seconds"]
            }
        }
        
        # 10. Status
        all_success = (
            emotional_analysis["success"] and
            report_generation["success"] and
            backend_result["success"]
        )
        result["status"] = "SUCCESS" if all_success else "FAILED"
        result["student_created"] = backend_result["success"]
        result["report_stored"] = backend_result["success"]
        result["analysis_completed"] = emotional_analysis["success"]
        
    except Exception as e:
        result["status"] = "ERROR"
        result["error"] = str(e)
    
    return result

async def run_performance_tests():
    """Executa todos os testes de desempenho t√©cnico"""
    print("="*80)
    print("üöÄ TESTE DE DESEMPENHO T√âCNICO - SISTEMA PSICOFLOW")
    print("="*80)
    print(f"Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    print(f"üìã Processando {TOTAL_CASES} triagens completas...\n")
    
    # Gerar casos de teste
    test_cases = [generate_test_case(i) for i in range(1, TOTAL_CASES + 1)]
    all_results = []
    
    # Executar cada triagem
    for i, test_case in enumerate(test_cases, 1):
        print(f"[{i}/{TOTAL_CASES}] Processando triagem {i}...")
        print(f"   Nome: {test_case['dados_pessoais']['nome']}")
        result = await execute_complete_triage(test_case)
        all_results.append(result)
        
        status_icon = "‚úÖ" if result["status"] == "SUCCESS" else "‚ùå"
        print(f"   {status_icon} Status: {result['status']}")
        
        if "metrics" in result:
            metrics = result["metrics"]
            print(f"\n   üìä TEMPOS DETALHADOS:")
            
            # Tempo de an√°lise emocional
            if "emotional_analysis" in metrics:
                emo_time = metrics["emotional_analysis"].get("time_seconds", 0)
                print(f"      ü§ñ An√°lise emocional IA: {emo_time:.2f}s")
            
            # Tempo de gera√ß√£o de relat√≥rio
            if "report_generation" in metrics:
                report_time = metrics["report_generation"].get("time_seconds", 0)
                print(f"      üìÑ Gera√ß√£o de relat√≥rio IA: {report_time:.2f}s")
            
            # Tempo do backend
            if "backend" in metrics:
                backend_time = metrics["backend"].get("time_seconds", 0)
                print(f"      üñ•Ô∏è  Backend (valida√ß√£o/armazenamento): {backend_time:.3f}s")
            
            # Tempo de an√°lise em tempo real (m√©dia)
            if "realtime_analysis" in metrics:
                realtime = metrics["realtime_analysis"]
                if realtime.get("avg_seconds", 0) > 0:
                    print(f"      üí¨ An√°lise em tempo real (m√©dia): {realtime['avg_seconds']:.2f}s")
                    print(f"         (min: {realtime.get('min_seconds', 0):.2f}s, max: {realtime.get('max_seconds', 0):.2f}s)")
            
            # Tempo total
            if "total_processing" in metrics:
                total_time = metrics["total_processing"].get("time_seconds", 0)
                print(f"      ‚ö° TEMPO TOTAL: {total_time:.2f}s")
            
            # Tempo de intera√ß√£o do usu√°rio (simulado)
            if "user_interaction" in metrics:
                inter_time = metrics["user_interaction"].get("time_seconds", 0)
                print(f"      üì± Intera√ß√£o do usu√°rio (simulado): {inter_time/60:.1f} minutos")
        
        print()
    # Calcular estat√≠sticas
    successful = [r for r in all_results if r["status"] == "SUCCESS"]
    
    # Estat√≠sticas agregadas
    interaction_times = [
        r["metrics"]["user_interaction"]["time_seconds"]
        for r in all_results if "metrics" in r and "user_interaction" in r["metrics"]
    ]
    
    backend_times = [
        r["metrics"]["backend"]["time_seconds"]
        for r in successful if "metrics" in r and "backend" in r["metrics"]
    ]
    
    emotional_analysis_times = [
        r["metrics"]["emotional_analysis"]["time_seconds"]
        for r in successful if "metrics" in r and "emotional_analysis" in r["metrics"]
    ]
    
    report_times = [
        r["metrics"]["report_generation"]["time_seconds"]
        for r in successful if "metrics" in r and "report_generation" in r["metrics"]
    ]
    
    total_processing_times = [
        r["metrics"]["total_processing"]["time_seconds"]
        for r in successful if "metrics" in r and "total_processing" in r["metrics"]
    ]
    
    realtime_times = []
    for r in all_results:
        if "metrics" in r and "realtime_analysis" in r["metrics"]:
            realtime_times.extend(r["metrics"]["realtime_analysis"]["times_seconds"])
    
    # Contadores
    students_created = sum(1 for r in successful if r.get("student_created", False))
    reports_stored = sum(1 for r in successful if r.get("report_stored", False))
    analyses_completed = sum(1 for r in successful if r.get("analysis_completed", False))
    
    # Gerar relat√≥rio
    report = {
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "total_triagens": TOTAL_CASES,
            "triagens_completas": len(successful),
            "estudantes_cadastrados_atualizados": students_created,
            "relatorios_gerados_armazenados": reports_stored,
            "analises_integradas_ia": analyses_completed,
            "taxa_sucesso": (len(successful) / TOTAL_CASES * 100) if TOTAL_CASES > 0 else 0
        },
        "performance_metrics": {
            "tempo_interacao_estudante": {
                "min_minutos": min(interaction_times) / 60 if interaction_times else 0,
                "max_minutos": max(interaction_times) / 60 if interaction_times else 0,
                "media_minutos": statistics.mean(interaction_times) / 60 if interaction_times else 0,
                "range": f"{min(interaction_times) / 60:.1f} - {max(interaction_times) / 60:.1f} minutos" if interaction_times else "N/A"
            },
            "tempo_backend": {
                "min_segundos": min(backend_times) if backend_times else 0,
                "max_segundos": max(backend_times) if backend_times else 0,
                "media_segundos": statistics.mean(backend_times) if backend_times else 0,
                "range": f"{min(backend_times):.3f} - {max(backend_times):.3f} segundos" if backend_times else "N/A"
            },
            "tempo_ia_analise_emocional": {
                "min_segundos": min(emotional_analysis_times) if emotional_analysis_times else 0,
                "max_segundos": max(emotional_analysis_times) if emotional_analysis_times else 0,
                "media_segundos": statistics.mean(emotional_analysis_times) if emotional_analysis_times else 0,
                "range": f"{min(emotional_analysis_times):.1f} - {max(emotional_analysis_times):.1f} segundos" if emotional_analysis_times else "N/A"
            },
            "tempo_ia_geracao_relatorio": {
                "min_segundos": min(report_times) if report_times else 0,
                "max_segundos": max(report_times) if report_times else 0,
                "media_segundos": statistics.mean(report_times) if report_times else 0,
                "range": f"{min(report_times):.1f} - {max(report_times):.1f} segundos" if report_times else "N/A"
            },
            "tempo_total_processamento": {
                "min_segundos": min(total_processing_times) if total_processing_times else 0,
                "max_segundos": max(total_processing_times) if total_processing_times else 0,
                "media_segundos": statistics.mean(total_processing_times) if total_processing_times else 0,
                "range": f"{min(total_processing_times):.1f} - {max(total_processing_times):.1f} segundos" if total_processing_times else "N/A"
            },
            "analise_emocional_tempo_real": {
                "min_segundos": min(realtime_times) if realtime_times else 0,
                "max_segundos": max(realtime_times) if realtime_times else 0,
                "media_segundos": statistics.mean(realtime_times) if realtime_times else 0,
                "range": f"{min(realtime_times):.1f} - {max(realtime_times):.1f} segundos" if realtime_times else "N/A"
            }
        },
        "detailed_results": all_results
    }
    
    # Salvar relat√≥rio
    filename = f"desempenho_tecnico_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # Imprimir resumo formatado
    print("="*80)
    print("üìä RESULTADOS DO DESEMPENHO T√âCNICO")
    print("="*80)
    
    print(f"\n‚úÖ PROCESSAMENTO:")
    print(f"   ‚Ä¢ Triagens processadas: {report['summary']['total_triagens']}")
    print(f"   ‚Ä¢ Estudantes cadastrados/atualizados: {report['summary']['estudantes_cadastrados_atualizados']}")
    print(f"   ‚Ä¢ Relat√≥rios t√©cnicos gerados e armazenados: {report['summary']['relatorios_gerados_armazenados']}")
    print(f"   ‚Ä¢ An√°lises integradas da IA: {report['summary']['analises_integradas_ia']}")
    print(f"   ‚Ä¢ Taxa de sucesso: {report['summary']['taxa_sucesso']:.1f}%")
    
    print(f"\n‚è±Ô∏è  M√âTRICAS DE TEMPO:")
    print(f"\n   üì± Tempo de intera√ß√£o do estudante com o chatbot:")
    print(f"      {report['performance_metrics']['tempo_interacao_estudante']['range']}")
    print(f"      (incluindo leitura e resposta das escalas)")
    
    print(f"\n   üñ•Ô∏è  Backend (valida√ß√£o e armazenamento):")
    print(f"      {report['performance_metrics']['tempo_backend']['range']}")
    print(f"      M√©dia: {report['performance_metrics']['tempo_backend']['media_segundos']:.3f}s")
    
    print(f"\n   ü§ñ M√≥dulo de IA - An√°lise emocional:")
    print(f"      {report['performance_metrics']['tempo_ia_analise_emocional']['range']}")
    print(f"      M√©dia: {report['performance_metrics']['tempo_ia_analise_emocional']['media_segundos']:.2f}s")
    
    print(f"\n   üìÑ M√≥dulo de IA - Gera√ß√£o de relat√≥rio t√©cnico:")
    print(f"      {report['performance_metrics']['tempo_ia_geracao_relatorio']['range']}")
    print(f"      M√©dia: {report['performance_metrics']['tempo_ia_geracao_relatorio']['media_segundos']:.2f}s")
    
    print(f"\n   ‚ö° Tempo total m√©dio por triagem:")
    print(f"      {report['performance_metrics']['tempo_total_processamento']['range']}")
    print(f"      M√©dia: {report['performance_metrics']['tempo_total_processamento']['media_segundos']:.2f}s")
    
    print(f"\n   üí¨ An√°lise emocional em tempo real (por mensagem):")
    print(f"      {report['performance_metrics']['analise_emocional_tempo_real']['range']}")
    print(f"      M√©dia: {report['performance_metrics']['analise_emocional_tempo_real']['media_segundos']:.2f}s")
    
    print("\n" + "="*80)
    print(f"üìÑ Relat√≥rio completo salvo em: {filename}")
    print("="*80)
    
    return report

if __name__ == "__main__":
    asyncio.run(run_performance_tests())